

model_id: stabilityai/stable-diffusion-2-1-base, black-forest-labs/FLUX.1-dev
dataset_id: coco, Gustavosta/Stable-Diffusion-Prompts 

overwrite_attacked_imgs: true, # if true, load raw, generate attacked, save attacked
                        false, # if false, load pre-attacked, 
calc_FID: false,        # if true, calculate FID
calc_CLIP: false,       # if true, calculate CLIP

# Attacks

# Distortion attacks
r_degree: [35, 75, 90, 120],
jpeg_ratio: [5, 10, 20 ],
crop_scale: [ 0.3,  0.7, 0.9 ],
crop_ratio: [ 0.3,  0.7, 0.9 ],
gaussian_blur_r: [ 6, 8, 10, 12 ],
gaussian_std: [0.1, 0.15, 0.2, 0.25, 0.3], # above 0.4 is just noise
brightness_factor: [4, 6, 8, 12],
rand_aug: null

# Adversarial attacks

# Adv. Embedding
adv_embed_resnet18: [2, 4, 6, 8]
adv_embed_clip: [2, 4, 6, 8]
adv_embed_klvae8: [2, 4, 6, 8]
adv_embed_sdxlvae: [2, 4, 6, 8]
adv_embed_klvae16: [2, 4, 6, 8]

# Adv. Surrogate classifiers
adv_surr_resnet18: [2, 4, 6, 8],
adv_surr_resnet18_path: "path/to/adv_cls_surr_resnet18.pth"




# CLIP model
reference_model: "ViT-g-14",                    # CLIP model to use
reference_model_pretrain: "laion2b_s12b_b42k",  # CLIP model pretrain to use, from huggingface (?)
  

