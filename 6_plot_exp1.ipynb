{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Functions for Exp1\n",
    "\n",
    "def plot_tpr_per_attack(args, results_df):\n",
    "\n",
    "    results_df['set_fpr'].unique()[0] # set_fpr should be the same for all experiments, so we can just take the first value\n",
    "\n",
    "    # drop the no_attack case from the results_df\n",
    "    results_df = results_df[results_df['attack_name'] != 'no_attack']\n",
    "\n",
    "\n",
    "    attack_names = results_df['attack_name'].unique()\n",
    "    wm_methods = results_df['wm_method'].unique()\n",
    "    models = results_df['model_id'].unique()\n",
    "\n",
    "    # order the attacks and methods based on the order in name_mapping\n",
    "    attack_names = np.array(sorted(attack_names, key=lambda x: list(ATTACK_NAME_MAPPING.keys()).index(x)))\n",
    "    wm_methods = np.array(sorted(wm_methods, key=lambda x: list(METHODS_NAME_MAPPING.keys()).index(x)))\n",
    "    models = np.array(sorted(models, key=lambda x: list(MODEL_NAME_MAPPING.keys()).index(x)))\n",
    "\n",
    "    # for each attack (rows), plot all 4 WM methods in 4 sublpots (cols), all 2 models as lines\n",
    "\n",
    "    ncols = wm_methods.shape[0] + 1 # per method, ülus one for title\n",
    "    nrows = attack_names.shape[0] # for each attack\n",
    "    fs = 10\n",
    "    fs_xticks = 8\n",
    "    fs_yticks = 8\n",
    "    fs_title = 14\n",
    "    y_adj = 0.92\n",
    "    title_height_ratio = 0.15#0.65\n",
    "    height_correction = 0\n",
    "    title = ( \n",
    "        f'Performance of watermarking methods under different attacks\\n'\n",
    "        f'for dataset \"{args.prompt_dataset}\" for experiments in \\n'\n",
    "        f'{args.dataset_identifier}'\n",
    "    )\n",
    "\n",
    "    fig, gs, title_axes = setup_gridspec_figure(\n",
    "        nrows=nrows, ncols=ncols ,\n",
    "        fs=fs, title=title, fs_title=fs_title,\n",
    "        y_adj=y_adj, title_height_ratio=title_height_ratio,\n",
    "        sp_width=2, sp_height=1.75, height_correction=height_correction,\n",
    "    )\n",
    "\n",
    "    # # set the titles for each row, as the attack names\n",
    "    # for i, ax in enumerate(title_axes):\n",
    "    #     ax.text(0.5, 0.4, ATTACK_NAME_MAPPING[attack_names[i]]['name'], fontsize=fs_title, fontweight=\"bold\", ha=\"center\", va=\"center\")\n",
    "                      \n",
    "    handles, labels = [], []\n",
    "\n",
    "    # loop through all attacks (rows), and then per attack, loop through all WM methods\n",
    "    for i, attack_name in enumerate(attack_names): # rows\n",
    "        attack_df = results_df[results_df['attack_name'] == attack_name]\n",
    "        if attack_name not in ATTACK_NAME_MAPPING:\n",
    "            continue\n",
    "\n",
    "        axes = [fig.add_subplot(gs[2*i +1, j]) for j in range(ncols)]\n",
    "        for j, wm_method in enumerate(np.concatenate((wm_methods, [\"title\"]))): # columns\n",
    "            if wm_method == \"title\": # last column is title of the attack\n",
    "                axes[j].axis('off')\n",
    "                axes[j].text(0.1, 0.5, ATTACK_NAME_MAPPING[attack_name]['name'], fontsize=fs, fontweight=\"bold\", ha=\"left\", va=\"center\")\n",
    "            else:\n",
    "                wm_df = attack_df[attack_df['wm_method'] == wm_method]\n",
    "                \n",
    "                # Set axis direction based on attack type\n",
    "                if ATTACK_NAME_MAPPING[attack_name]['order'] == 'low-to-high':\n",
    "                    axes[j].invert_xaxis()\n",
    "                    \n",
    "                if i == 0:\n",
    "                    axes[j].set_title(METHODS_NAME_MAPPING[wm_method], fontsize=fs)\n",
    "                \n",
    "                axes[j].set_yticks(np.arange(0, 1.1, 0.25))\n",
    "                axes[j].set_yticklabels(np.arange(0, 1.1, 0.25), fontsize=fs_yticks)\n",
    "                axes[j].set_ylim([-0.1, 1.1])\n",
    "                axes[j].grid(True)\n",
    "                # set top and right spines to invisible\n",
    "                axes[j].spines['top'].set_visible(False)\n",
    "                axes[j].spines['right'].set_visible(False)\n",
    "\n",
    "                if j == 0:# Add y-axis label to the first plot in each row\n",
    "                    axes[j].set_ylabel(\"TPR@FPR=0.01\")\n",
    "                else:# disable y-axis labels for all but the first column\n",
    "                    plt.setp(axes[j].get_yticklabels(), visible=False)\n",
    "                    plt.setp(axes[j].get_yticklines(), visible=False)\n",
    "\n",
    "                for model in models: # lines\n",
    "                    model_df = wm_df[wm_df['model_id'] == model]\n",
    "                    # Check if the model_df is empty\n",
    "                    if model_df.empty:\n",
    "                        print(f\"\\nWarning: No data for {attack_name}, {wm_method}, {model}\\n\")\n",
    "                        continue\n",
    "\n",
    "                    if attack_name == 'no_attack':\n",
    "                        # No need to order the attack strengths for the no attack case\n",
    "                        strengths = model_df['attack_strength'].unique()\n",
    "                        results = model_df['tpr_empirical'].values\n",
    "                        ci_lower = model_df['tpr_ci_lower_percentile'].values\n",
    "                        ci_upper = model_df['tpr_ci_upper_percentile'].values\n",
    "                    else:\n",
    "                        strengths, results, ci_lower, ci_upper = order_attack_strengths(\n",
    "                            ATTACK_NAME_MAPPING[attack_name]['order'],\n",
    "                            model_df['attack_strength'], \n",
    "                            model_df['tpr_empirical'],\n",
    "                            model_df['tpr_ci_lower_percentile'],\n",
    "                            model_df['tpr_ci_upper_percentile'],\n",
    "                            ATTACK_NAME_MAPPING[attack_name]['cast_to_int'],\n",
    "                        )\n",
    "                    \n",
    "                    label = MODEL_NAME_MAPPING[model]['name']\n",
    "                    \n",
    "                    # Plot using actual strength values\n",
    "                    line, = axes[j].plot(strengths, results,\n",
    "                                marker=MODEL_NAME_MAPPING[model]['marker'],\n",
    "                                linestyle=MODEL_NAME_MAPPING[model]['line'],\n",
    "                                label=label,\n",
    "                                color=MODEL_NAME_MAPPING[model]['color'])\n",
    "                    \n",
    "                    if (not np.isnan(ci_lower).any() and not np.isnan(ci_upper).any()) or (len(ci_lower) > 0 and len(ci_upper) > 0):\n",
    "                        axes[j].fill_between(strengths, ci_lower, ci_upper, color=MODEL_NAME_MAPPING[model]['color'], alpha=0.2)\n",
    "                        if attack_name == 'no_attack':\n",
    "                            axes[j].plot(strengths, ci_lower, color=MODEL_NAME_MAPPING[model]['color'], alpha=0.2, marker='x', linestyle='--')\n",
    "                            axes[j].plot(strengths, ci_upper, color=MODEL_NAME_MAPPING[model]['color'], alpha=0.2, marker='x', linestyle='--')\n",
    "\n",
    "                                \n",
    "                    if label not in labels:\n",
    "                        handles.append(line)\n",
    "                        labels.append(label)\n",
    "\n",
    "                    # Set only the actual strength values as ticks\n",
    "                    axes[j].set_xticks(strengths)\n",
    "                    axes[j].set_xticklabels(strengths, fontsize=fs_xticks)\n",
    "                    #axes[j].set_xlim([strengths[0]-0.1, strengths[-1]+0.1])\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "    fig.legend(loc='lower center', bbox_to_anchor=(0.2, 0.08, 0.5, 0.5), ncol=len(models), handles=handles, labels=labels)\n",
    "    \n",
    "\n",
    "    plt.savefig(args.output_plot, bbox_inches='tight', dpi=300)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    print(f\"\\nPlot saved to {args.output_plot}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: No data for r_degree, prc, sd\n",
      "\n",
      "\n",
      "Warning: No data for adv_embed_klvae8, rid, flux\n",
      "\n",
      "\n",
      "Plot saved to experiments/exp1/_results/coco/num_200_fpr_0.01_cfg_3.0_wmch_16/num_200_fpr_0.01_cfg_3.0_wmch_16_plot.pdf\n"
     ]
    }
   ],
   "source": [
    "args = Namespace()\n",
    "args.exp_name = 'exp1'\n",
    "\n",
    "\n",
    "# specify which experimental setup we want to plot\n",
    "args.num_imgs = 200\n",
    "args.prompt_dataset = 'coco'\n",
    "\n",
    "# for exp1, we merge results over wmch_16 for Flux and wmch_4 for SD\n",
    "args.dataset_identifier = [f'num_{args.num_imgs}_fpr_0.01_cfg_3.0_wmch_16', \n",
    "                           f'num_{args.num_imgs}_fpr_0.01_cfg_3.0_wmch_4'] \n",
    "\n",
    "\n",
    "# create the output directories and ffilenames\n",
    "args.input_dir = os.path.join('experiments', args.exp_name)\n",
    "args.output_dir = os.path.join('experiments', args.exp_name, '_results', args.prompt_dataset,  args.dataset_identifier[0])\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "args.output_plot = os.path.join(args.output_dir, args.dataset_identifier[0] + '_plot.pdf')\n",
    "args.merged_result_csv = os.path.join(args.output_dir, args.dataset_identifier[0] + '_merged.csv')\n",
    "\n",
    "# merged results already created in 5_merge_results.py\n",
    "results_df = pd.read_csv(args.merged_result_csv)\n",
    "\n",
    "# 1. plot TPR vs attack strength\n",
    "plot_tpr_per_attack(args, results_df)\n",
    "\n",
    "# # 2. plot TPR vs CLIP \n",
    "# xmin = results_df['clip_score_wm'].min()\n",
    "# xmax = results_df['clip_score_wm'].max()\n",
    "# plot_tpr_per_metric(\n",
    "#     args, \n",
    "#     results_df, \n",
    "#     metric_name=\"clip_score\", \n",
    "#     metric_column=\"clip_score_wm\",\n",
    "#     title_suffix=\"CLIP similarity score\",\n",
    "#     xlabel=\"CLIP score (↑)\",\n",
    "#     xlim=[xmin, xmax]\n",
    "# )\n",
    "\n",
    "# # 3. plot TPR vs diff \n",
    "# xmin = results_df['wm_diff'].min()\n",
    "# xmax = results_df['wm_diff'].max()\n",
    "# plot_tpr_per_metric(\n",
    "#     args, \n",
    "#     results_df, \n",
    "#     metric_name=\"wm_diff\", \n",
    "#     metric_column=\"wm_diff\",\n",
    "#     title_suffix=\"Abs. Mean Difference (originial - recovered)\",\n",
    "#     xlabel=\"Diff (↓)\",\n",
    "#     xlim=[xmin, xmax]\n",
    "# )\n",
    "\n",
    "# # 4. plot TPR vs FID (WM vs COCO)\n",
    "# xmin = results_df['fid_wm_coco'].min()\n",
    "# xmax = results_df['fid_wm_coco'].max()\n",
    "# plot_tpr_per_metric(\n",
    "#     args, \n",
    "#     results_df, \n",
    "#     metric_name=\"fid_coco\", \n",
    "#     metric_column=\"fid_wm_coco\",\n",
    "#     title_suffix=\"FID (WM vs COCO)\",\n",
    "#     xlabel=\"FID (↓)\",\n",
    "#     xlim=[xmin, xmax]\n",
    "# )\n",
    "\n",
    "# # 5. plot TPR vs FID (WM vs NOWM)\n",
    "# xmin = results_df['fid_wm_nowm'].min()\n",
    "# xmax = results_df['fid_wm_nowm'].max()\n",
    "# plot_tpr_per_metric(\n",
    "#     args, \n",
    "#     results_df, \n",
    "#     metric_name=\"fid_wm_nowm\", \n",
    "#     metric_column=\"fid_wm_nowm\",\n",
    "#     title_suffix=\"FID (WM vs NOWM)\",\n",
    "#     xlabel=\"FID (↓)\",\n",
    "#     xlim=[xmin, xmax]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
